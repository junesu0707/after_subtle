{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploit kp-moseq module for comparing occurrence rate of each subcluster (=syllables in kp-moseq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_results_subtle(project_dir, model_name):\n",
    "    \"\"\"\n",
    "    Load the subclusters.csv files from the specified model directory and return the results as a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    project_dir (str): The directory containing the model directories.\n",
    "    model_name (str): The name of the model directory.\n",
    "\n",
    "    Returns:\n",
    "    results_dict: A dictionary containing the subclusters data for each recording.\n",
    "    \"\"\"\n",
    "    results_dict = {}\n",
    "    \n",
    "    model_dir = os.path.join(project_dir, model_name)\n",
    "    \n",
    "    # traverse all directories within the model directory (i.e., recording_names)\n",
    "    for recording_name in os.listdir(model_dir):\n",
    "        recording_path = os.path.join(model_dir, recording_name)\n",
    "        \n",
    "        # Verify that the current path is a directory\n",
    "        if os.path.isdir(recording_path):\n",
    "            subclusters_file = os.path.join(recording_path, 'subclusters.csv')\n",
    "            \n",
    "            # Verify that the subclusters.csv file exists\n",
    "            if os.path.isfile(subclusters_file):\n",
    "                subclusters_data = pd.read_csv(subclusters_file, header=None)\n",
    "                subclusters_array = subclusters_data.values.flatten()   # convert to 1D array (same with kp-moseq format)\n",
    "                \n",
    "                results_dict[recording_name] = {'syllable': subclusters_array}\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def concatenate_stateseqs(stateseqs, mask=None):\n",
    "    \"\"\"\n",
    "    Concatenate state sequences, optionally applying a mask.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stateseqs: ndarray of shape (..., t), or dict or list of such arrays\n",
    "        Batch of state sequences where the last dim indexes time, or a\n",
    "        dict/list containing state sequences as 1d arrays.\n",
    "\n",
    "    mask: ndarray of shape (..., >=t), default=None\n",
    "        Binary indicator for which elements of `stateseqs` are valid,\n",
    "        used in the case where `stateseqs` is an ndarray. If `mask`\n",
    "        contains more time-points than `stateseqs`, the initial extra\n",
    "        time-points will be ignored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stateseqs_flat: ndarray\n",
    "        1d array containing all state sequences\n",
    "    \"\"\"\n",
    "    if isinstance(stateseqs, dict):\n",
    "        stateseq_flat = np.hstack(list(stateseqs.values()))\n",
    "    elif isinstance(stateseqs, list):\n",
    "        stateseq_flat = np.hstack(stateseqs)\n",
    "    elif mask is not None:\n",
    "        stateseq_flat = stateseqs[mask[:, -stateseqs.shape[1] :] > 0]\n",
    "    else:\n",
    "        stateseq_flat = stateseqs.flatten()\n",
    "    return stateseq_flat\n",
    "\n",
    "\n",
    "def get_frequencies(stateseqs, mask=None, num_states=None, runlength=True):\n",
    "    \"\"\"\n",
    "    Get state frequencies for a batch of state sequences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stateseqs: ndarray of shape (..., t), or dict or list of such arrays\n",
    "        Batch of state sequences where the last dim indexes time, or a\n",
    "        dict/list containing state sequences as 1d arrays.\n",
    "\n",
    "    mask: ndarray of shape (..., >=t), default=None\n",
    "        Binary indicator for which elements of `stateseqs` are valid,\n",
    "        used in the case where `stateseqs` is an ndarray. If `mask`\n",
    "        contains more time-points than `stateseqs`, the initial extra\n",
    "        time-points will be ignored.\n",
    "\n",
    "    num_states: int, default=None\n",
    "        Number of different states. If None, the number of states will\n",
    "        be set to `max(stateseqs)+1`.\n",
    "\n",
    "    runlength: bool, default=True (빈도로 계산할지,  duration으로 계산할지)\n",
    "        Whether to count frequency by the number of instances of each\n",
    "        state (True), or by the number of frames in each state (False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    frequencies: 1d array\n",
    "        Frequency of each state across all state sequences\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> stateseqs = {\n",
    "        'name1': np.array([1, 1, 2, 2, 2, 3]),\n",
    "        'name2': np.array([0, 0, 0, 1])}\n",
    "    >>> get_frequencies(stateseqs, runlength=True)\n",
    "    array([0.2, 0.4, 0.2, 0.2])\n",
    "    >>> get_frequencies(stateseqs, runlength=False)\n",
    "    array([0.3, 0.3, 0.3, 0.1])\n",
    "    \"\"\"\n",
    "    stateseq_flat = concatenate_stateseqs(stateseqs, mask=mask).astype(int)\n",
    "\n",
    "    if runlength:\n",
    "        state_onsets = np.pad(np.diff(stateseq_flat).nonzero()[0] + 1, (1, 0))\n",
    "        stateseq_flat = stateseq_flat[state_onsets]\n",
    "\n",
    "    counts = np.bincount(stateseq_flat, minlength=num_states)\n",
    "    frequencies = counts / counts.sum()\n",
    "    return frequencies\n",
    "\n",
    "\n",
    "def compute_subtle_df(project_dir, model_name, *, fps=30, index_filename=\"index.csv\"):\n",
    "    \"\"\"Compute moseq dataframe from results dict that contains all kinematic\n",
    "    values by frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_dir : str\n",
    "        the path to the project directory\n",
    "    model_name : str\n",
    "        the name of the model directory\n",
    "    results_dict : dict\n",
    "        dictionary of results from model fitting\n",
    "    use_bodyparts : bool\n",
    "        boolean flag whether to include data for bodyparts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subtle_df : pandas.DataFrame\n",
    "        the dataframe that contains kinematic data for each frame\n",
    "    \"\"\"\n",
    "\n",
    "    # load model results\n",
    "    results_dict = load_results_subtle(project_dir, model_name)\n",
    "\n",
    "    # load index file\n",
    "    index_filepath = os.path.join(project_dir, index_filename)\n",
    "    if os.path.exists(index_filepath):\n",
    "        index_data = pd.read_csv(index_filepath, index_col=False)\n",
    "    else:\n",
    "        print(\n",
    "            \"index.csv not found, if you want to include group information for each video, please run the Assign Groups widget first\"\n",
    "        )\n",
    "\n",
    "    recording_name = []\n",
    "    syllable = []\n",
    "    frame_index = []\n",
    "    s_group = []\n",
    "\n",
    "    for k, v in results_dict.items():\n",
    "        n_frame = v[\"syllable\"].shape[0]\n",
    "        recording_name.append([str(k)] * n_frame)\n",
    "\n",
    "        if index_data is not None:\n",
    "            # find the group for each recording from index data\n",
    "            s_group.append(\n",
    "                [index_data[index_data[\"name\"] == k][\"group\"].values[0]] * n_frame\n",
    "            )\n",
    "        else:\n",
    "            # no index data\n",
    "            s_group.append([\"default\"] * n_frame)\n",
    "        frame_index.append(np.arange(n_frame))\n",
    "        \n",
    "        # add syllable data\n",
    "        syllable.append(v[\"syllable\"])\n",
    "\n",
    "    # construct dataframe\n",
    "    subtle_df = pd.DataFrame(np.concatenate(recording_name), columns=[\"name\"])\n",
    "    subtle_df[\"syllable\"] = np.concatenate(syllable)\n",
    "    subtle_df[\"frame_index\"] = np.concatenate(frame_index)\n",
    "    subtle_df[\"group\"] = np.concatenate(s_group)\n",
    "\n",
    "    # compute syllable onset\n",
    "    change = np.diff(subtle_df[\"syllable\"]) != 0\n",
    "    indices = np.where(change)[0]\n",
    "    indices += 1\n",
    "    indices = np.concatenate(([0], indices))\n",
    "\n",
    "    onset = np.full(subtle_df.shape[0], False)\n",
    "    onset[indices] = True\n",
    "    subtle_df[\"onset\"] = onset\n",
    "    return subtle_df\n",
    "\n",
    "\n",
    "def compute_stats_subtle_df(\n",
    "    project_dir,\n",
    "    model_name,\n",
    "    subtle_df,\n",
    "    min_frequency=0.001,\n",
    "    groupby=[\"group\", \"name\"],\n",
    "    fps=30,\n",
    "    index_filename=\"index.csv\"\n",
    "):\n",
    "    \"\"\"Summary statistics for syllable frequencies and kinematic values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subtle_df : pandas.DataFrame\n",
    "        the dataframe that contains kinematic data for each frame\n",
    "    threshold : float, optional\n",
    "        usge threshold for the syllable to be included, by default 0.005\n",
    "    groupby : list, optional\n",
    "        the list of column names to group by, by default ['group', 'name']\n",
    "    fps : int, optional\n",
    "        frame per second information of the recording, by default 30\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stats_df : pandas.DataFrame\n",
    "        the summary statistics dataframe for syllable frequencies and kinematic values\n",
    "    \"\"\"\n",
    "    # compute runlength encoding for syllable\n",
    "\n",
    "    # load model results\n",
    "    results_dict = load_results_subtle(project_dir, model_name)\n",
    "    syllable = {k: res[\"syllable\"] for k, res in results_dict.items()}\n",
    "    # frequencies is array of frequencies for sorted syllable [syll_0, syll_1...]\n",
    "    frequencies = get_frequencies(syllable)\n",
    "    syll_include = np.where(frequencies > min_frequency)[0]\n",
    "\n",
    "    # add group information\n",
    "    # load index file\n",
    "    index_filepath = os.path.join(project_dir, index_filename)\n",
    "    if os.path.exists(index_filepath):\n",
    "        index_df = pd.read_csv(index_filepath, index_col=False)\n",
    "    else:\n",
    "        print(\n",
    "            \"index.csv not found, if you want to include group information for each video, please run the Assign Groups widget first\"\n",
    "        )\n",
    "\n",
    "    # construct frequency dataframe\n",
    "    # syllable frequencies within one session add up to 1\n",
    "    frequency_df = []\n",
    "    for k, v in results_dict.items():\n",
    "        syll_freq = get_frequencies(v[\"syllable\"])\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"name\": k,\n",
    "                \"group\": index_df[index_df[\"name\"] == k][\"group\"].values[0],\n",
    "                \"syllable\": np.arange(len(syll_freq)),\n",
    "                \"frequency\": syll_freq,\n",
    "            }\n",
    "        )\n",
    "        frequency_df.append(df)\n",
    "    frequency_df = pd.concat(frequency_df)\n",
    "    if \"name\" not in groupby:\n",
    "        frequency_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "    # filter out syllable that are used less than threshold in all recordings\n",
    "    filtered_df = subtle_df[subtle_df[\"syllable\"].isin(syll_include)].copy()\n",
    "\n",
    "    # TODO: hard-coded heading for now, could add other scalars\n",
    "    features = filtered_df.groupby(groupby + [\"syllable\"]).size().reset_index().drop(columns=0)\n",
    "    \n",
    "    # get durations\n",
    "    trials = filtered_df[\"onset\"].cumsum()\n",
    "    trials.name = \"trials\"\n",
    "    durations = filtered_df.groupby(groupby + [\"syllable\"] + [trials])[\"onset\"].count()\n",
    "    # average duration in seconds\n",
    "    durations = durations.groupby(groupby + [\"syllable\"]).mean() / fps\n",
    "    durations.name = \"duration\"\n",
    "    # only keep the columns we need\n",
    "    durations = durations.fillna(0).reset_index()[groupby + [\"syllable\", \"duration\"]]\n",
    "\n",
    "    stats_df = pd.merge(features, frequency_df, on=groupby + [\"syllable\"])\n",
    "    stats_df = pd.merge(stats_df, durations, on=groupby + [\"syllable\"])\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "project_dir=r'C:\\Users\\MyPC\\Desktop\\git\\SUBTLE_June\\project\\neuroventi\\model1' # the full path to the project directory\n",
    "model_name='results_testset1' # name of model to analyze (e.g. something like `2023_05_23-15_19_03`)\n",
    "index_filename = \"index.csv\"\n",
    "fps = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model results\n",
    "results_dict = load_results_subtle(project_dir, model_name)\n",
    "\n",
    "# load index file\n",
    "index_filepath = os.path.join(project_dir, index_filename)\n",
    "if os.path.exists(index_filepath):\n",
    "    index_data = pd.read_csv(index_filepath, index_col=False)\n",
    "\n",
    "recording_name = []\n",
    "syllable = []\n",
    "frame_index = []\n",
    "s_group = []\n",
    "\n",
    "for k, v in results_dict.items():\n",
    "    n_frame = v[\"syllable\"].shape[0]\n",
    "    recording_name.append([str(k)] * n_frame)\n",
    "\n",
    "    if index_data is not None:\n",
    "        # find the group for each recording from index data\n",
    "        s_group.append(\n",
    "            [index_data[index_data[\"name\"] == k][\"group\"].values[0]] * n_frame\n",
    "        )\n",
    "    else:\n",
    "        # no index data\n",
    "        s_group.append([\"default\"] * n_frame)\n",
    "    frame_index.append(np.arange(n_frame))\n",
    "    \n",
    "    # add syllable data\n",
    "    syllable.append(v[\"syllable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>name</th>\n",
       "      <th>syllable</th>\n",
       "      <th>frequency</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1</td>\n",
       "      <td>B1_Trial 1.mp4.txt_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.071978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G1</td>\n",
       "      <td>B1_Trial 1.mp4.txt_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020387</td>\n",
       "      <td>0.076008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G1</td>\n",
       "      <td>B1_Trial 1.mp4.txt_1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.198841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G1</td>\n",
       "      <td>B1_Trial 1.mp4.txt_1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029996</td>\n",
       "      <td>0.049784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G1</td>\n",
       "      <td>B1_Trial 1.mp4.txt_1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024153</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>G3</td>\n",
       "      <td>B3_Trial 4.mp4.txt_7</td>\n",
       "      <td>61</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.096124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>G3</td>\n",
       "      <td>B3_Trial 4.mp4.txt_7</td>\n",
       "      <td>62</td>\n",
       "      <td>0.014146</td>\n",
       "      <td>0.063363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>G3</td>\n",
       "      <td>B3_Trial 4.mp4.txt_7</td>\n",
       "      <td>63</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.063574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>G3</td>\n",
       "      <td>B3_Trial 4.mp4.txt_7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.009813</td>\n",
       "      <td>0.065368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>G3</td>\n",
       "      <td>B3_Trial 4.mp4.txt_7</td>\n",
       "      <td>68</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.068927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2376 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     group                  name  syllable  frequency  duration\n",
       "0       G1  B1_Trial 1.mp4.txt_1         0   0.023633  0.071978\n",
       "1       G1  B1_Trial 1.mp4.txt_1         1   0.020387  0.076008\n",
       "2       G1  B1_Trial 1.mp4.txt_1         2   0.014933  0.198841\n",
       "3       G1  B1_Trial 1.mp4.txt_1         3   0.029996  0.049784\n",
       "4       G1  B1_Trial 1.mp4.txt_1         4   0.024153  0.064516\n",
       "...    ...                   ...       ...        ...       ...\n",
       "2371    G3  B3_Trial 4.mp4.txt_7        61   0.005480  0.096124\n",
       "2372    G3  B3_Trial 4.mp4.txt_7        62   0.014146  0.063363\n",
       "2373    G3  B3_Trial 4.mp4.txt_7        63   0.012361  0.063574\n",
       "2374    G3  B3_Trial 4.mp4.txt_7        64   0.009813  0.065368\n",
       "2375    G3  B3_Trial 4.mp4.txt_7        68   0.007519  0.068927\n",
       "\n",
       "[2376 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtle_df = compute_subtle_df(project_dir, model_name, fps=fps, index_filename=index_filename) \n",
    "subtle_df\n",
    "\n",
    "stats_subtle_df = compute_stats_subtle_df(\n",
    "    project_dir,\n",
    "    model_name,\n",
    "    subtle_df, \n",
    "    min_frequency=0.005,       # threshold frequency for including a syllable in the dataframe\n",
    "    groupby=['group', 'name'], # column(s) to group the dataframe by\n",
    "    fps=fps,\n",
    "    index_filename=index_filename)                    # frame rate of the video from which keypoints were inferred\n",
    "\n",
    "stats_subtle_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save moseq_df or stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved `subtle_df` dataframe to C:\\Users\\MyPC\\Desktop\\git\\SUBTLE_June\\project\\neuroventi\\model1\\results_testset1\n",
      "Saved `stats_subtle_df` dataframe to C:\\Users\\MyPC\\Desktop\\git\\SUBTLE_June\\project\\neuroventi\\model1\\results_testset1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# save moseq_df\n",
    "save_dir = os.path.join(project_dir, model_name) # directory to save the moseq_df dataframe\n",
    "subtle_df.to_csv(os.path.join(save_dir, 'subtle_df.csv'), index=False)\n",
    "print('Saved `subtle_df` dataframe to', save_dir)\n",
    "\n",
    "# save stats_df\n",
    "save_dir = os.path.join(project_dir, model_name)\n",
    "stats_subtle_df.to_csv(os.path.join(save_dir, 'stats_subtle_df.csv'), index=False)\n",
    "print('Saved `stats_subtle_df` dataframe to', save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SUBTLE",
   "language": "python",
   "name": "subtle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
